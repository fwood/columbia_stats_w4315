% Essential Formatting

\documentclass[12pt]{article}
\usepackage{epsfig,amsmath,amsthm,amssymb}
\usepackage[questions, answersheet]{urmathtest}[2001/05/12]
%\usepackage[answersheet]{urmathtest}[2001/05/12]
%\usepackage[answers]{urmathtest}[2001/05/12]


% For use with pdflatex
% \pdfpagewidth\paperwidth
% \pdfpageheight\paperheight

% Basic User Defs

\def\ds{\displaystyle}

\newcommand{\ansbox}[1]
{\work{
  \pos\hfill \framebox[#1][l]{ANSWER:\rule[-.3in]{0in}{.7in}}
}{}}

\newcommand{\ansrectangle}
{\work{
  \pos\hfill \framebox[6in][l]{ANSWER:\rule[-.3in]{0in}{.7in}}
}{}}


% Beginning of the Document

\begin{document}
\examtitle{LINEAR REGRESSION MODELS W4315}{HOMEWORK 6}%{10/22/2009}

 \begin{center}
 Due: 03/09/2010\\
  Instructor: Frank Wood
 \end{center}
%%\studentinfo
\instructions{
  %\textbf{Circle your Instructor's Name along with the Lecture Time:}



  \begin{itemize}
  \item
    \textbf{Please show all your work.
            You may use back pages if necessary.}
  %\item
   % \textbf{Please put your \underline{simplified}
   %         final answers in the spaces provided.}
  \end{itemize}
} \finishfirstpage
% Problems Start Here % ----------------------------------------------------- %


\problem{20} {
 Refer to the design matrix given in ``hw6p1.dat'' on the course website.
 Read it into MATLAB ( the first  $\textbf{1}$ column is already added). Use ``load hw6p1.dat'' to load the file. What is the most complex model in terms of number of parameters
 that one could fit to this data?

 Extra credit(5 points): If you fit a model with this number of parameters, how could  you figure out which  should be non-zero?
 }
 { \vfill
  \answer
} { 
The most complex model has 61 parameters. \\
For the extra credit, good answers may include: perform t-test for each variable; Principal Component Analysis; some kind of regularization.
}



\problem{35}{	 	
 Consider the classical matrix approach to multiple regression, i.e.
	 	
 \begin{center}
	 	
 $\bf y=X\mathbf{\beta}+\mathbf{\epsilon}$
	 	
 \end{center}
	 	
 where $\mathbf{X}$ is a $n\times p$ design matrix whose first column is all 1's, $\epsilon\sim N(\textbf{0},\textbf{I})$ and $\bf I$ is an identity matrix. Prove the following:\\
	 	
 a. The sum of squares error $SSE={\mathbf{e}}'{\mathbf{e}}$ can be written in a matrix form:
	 	
 \[SSE=\textbf{y}'(\textbf{I}-\textbf{X}(\textbf{X}'\textbf{X})^{-1}\textbf{X}')\textbf{y} \]
	 	
 b. We call the RHS of (2) a quadratic form. Prove that the matrix $\textbf{A}=\mathbf{I}-\mathbf{X}(\mathbf{X}'\mathbf{X})^{-1} \mathbf{X}'$ is an idempotent matrix.\\
	 	
 c. Prove that the rank of $\textbf{A}$ defined in part (b) is $n-p$.\\
	 	
  N.B. $p$ columns in design matrix means there are $p-1$ predictors plus 1 intercept term. In your solutions please clearly notate the dimensions of all of the matrices.

 }
 { \vfill
  \answer
}
{ 
a. Note that $\hat{\beta}=(X'X)^{-1}X'y$
\begin{eqnarray*}
SSE&=&(y-X\hat{\beta})'(y-X\hat{\beta})\\
&=& (y-X(X'X)^{-1}X'y)'(y-X(X'X)^{-1}X'y)\\
&=& y'(I-X(X'X)^{-1}X')(I-X(X'X)^{-1}X')y\\
&=& y'(I-X(X'X)^{-1}X')y
\end{eqnarray*}
b. It has already been shown in proof for part a.\\
c. First, notice that idempotent matrix only has eigenvalues 0 and 1, which mean that its
rank equals to its trace. Then
\begin{eqnarray*}
rank(I - X(X'X)^{-1}X') &=& tr(I_n - X(X'X)^{-1}X')\\
&=& tr(I_n) - tr(X(X'X)^{-1}X')\\
&=& n - tr((X'X)^{-1}X'X)\\
&=& n - tr(I_p) = n - p
\end{eqnarray*}
In the above displays, we use the two properties of trace, namely, $tr(A+B) = tr(A)+tr(B)$
and $tr(AB) = tr(BA)$.\\
}	


\problem{45}{
 Suppose $X_1,...,X_n$ are i.i.d. samples from $N(0,\sigma^2)$. Denote $\bar{X}$ as the sample mean. Prove $S=\displaystyle\sum_{i=1}^n (X_i-\bar{X})^2 \sim \sigma^2 \chi^2(n-1)$ following the steps below using Cochran's theorem: \\
 a. Remember that we have the decomposition
 \begin{eqnarray*}
 \displaystyle \sum_{i=1}^n X_i^2=\sum_{i=1}^n (X_i-\bar{X})^2+n\bar{X}^2
 \end{eqnarray*}
 Show the matrices corresponding to all the three quadratic terms in (3).\\
 b. Derive the rank of each matrix above. \\
 c. Use Cochran's theorem to prove $S\sim \sigma^2 \chi^2(n-1)$.
}
{ \vfill
\answer
}
{
a. Denote $\textbf{X} =(X_1,...,X_n)'$, then we have the matrix form of (1) as
\begin{center}
$\textbf{X}'\textbf{X}=\textbf{X}'(\textbf{I}-\frac{1}{n}\textbf{J})\textbf{X}+\textbf{X}'\frac{1}{n}\textbf{J}\textbf{X}$
\end{center}
where $\textbf{J}$ is an $n \times n$ matrix whose elements are all 1.
So the corresponding matrics for (1) are respetively $\textbf{I},\bf{I}-\frac{1}{n}\textbf{J},\frac{1}{n}\textbf{J}$.\\
b. \\
Since $\textbf{I}$ is an $n \times n$ identity matrix, so $r(\textbf{I})=n$.\\
For the 2nd matrix, it's easy to verify that $\textbf{I}-\frac{1}{n}\textbf{J}$ is idempotent, since
\begin{align*}
(\textbf{I}-\frac{1}{n}\textbf{J})(\textbf{I}-\frac{1}{n}\textbf{J})&=\textbf{I}-\frac{2}{n}\textbf{J}+\frac{1}{n^2}\textbf{J}^2\\
                                                                       &=\textbf{I}-\frac{2}{n}\textbf{J}+\frac{1}{n^2}n\textbf{J}\\
                                                                       &=\textbf{I}-\frac{2}{n}\textbf{J}+\frac{1}{n}\textbf{J}\\
                                                                       &=\textbf{I}-\frac{1}{n}\textbf{J}
\end{align*}
The 2nd equation holds since $\textbf{J}^2=n\textbf{J}$. Now that $\bf{I}-\frac{1}{n}\bf{J}$ is idempotent, we have
\begin{align*}
rk(\textbf{I}-\frac{1}{n}\textbf{J})&=tr(\textbf{I}-\frac{1}{n}\textbf{J})\\
                                                  &=tr(\textbf{I})-tr(\frac{1}{n}\textbf{J})\\
                                                  &=n-\frac{1}{n}\times n\\
                                                  &=n-1
\end{align*}
where $tr(\textbf{A})$ stands for the trace of matrix $\textbf{A}$, $rk(\textbf{A})$ for the rank of it. It's apparent from the definition of rank of a matrix that $rk(\frac{1}{n}\textbf{J})=1$.\\
c. Since $rk(\textbf{I})=rk(\textbf{I}-\frac{1}{n}\textbf{J})+rk(\frac{1}{n}\textbf{J})$, we can directly apply Cochran's theorem, so $S\sim \sigma^2 \chi^2(n-1)$.
}


\end{document}
